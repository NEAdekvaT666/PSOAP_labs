<font size="5"><b>Выбранные домены:</b></font>
<font size="4">

1. Googleblog.blogspot.com

2. Teradata.com

3. Smithmicro.com

4. Hitachi.com

5. Gateway.com

6. Research.microsoft.com

7. Aspiresys.com

8. Crossriver.com

9. Packardbell.com

10. Vertica.com

11. Sun.com

12. Scnsoft.com

13. Dmoz.org

14. Mom.me

15. Avs4you.com

</font>

<br><font size="5"><b>Какие данные должны собрать?</b></font>
<font size="4">

1. `Домен`;

2. `IP-адрес`;

3. `IP Netblock`;

4. `Страна, город`;

5. `Адрес`;

6. `Телефон`;

7. `Хостинг (при наличии)`;

8. `Открытые порты`;

9. `Используемые web-технологии на сайте`.

</font>
<br><font size="5"><b>Используемое ПО:</b></font>
<font size="4">

1. `Kali Linux 2020.2`

2. `arp`

3. `whois`

4. `nmap`

5. `rappalyzer`

</font>
<br><font size="5"><b>Варианты решения задач:</b></font>
<font size="4">

1. Собрать информацию вручную с помощью веб-браузера, инструментов whois, dig, nmap и т.д.;

2. Использоавть интегрированные инструменты такие как SpiderFoot, Maltego CE, Datasploit, Recon-ng;

3. Самостоятельно разработать (для образовательных целей) автоматизированное решение для сбора информации.

В данной работе используется третий вариант решения задачи.

</font>
<br><font size="5"><b>Общий ход выполнения работы:</b></font>
<font size="4">

1. Написание функции для сбора требуемой информации;

2. Сбор информации по компаниям/

</font>
<br><font size="5"><b>Ход работы:</b></font>
```{r, cache=TRUE, message=FALSE, warning=FALSE} 
library(tidyverse)

get_sum_df <- function(company_url) {
  country_state <- NA
  
  arp <- system2('arp', company_url, stdout = TRUE)
  ip <- arp %>%
    grep(pattern = company_url, value = TRUE) %>%
      str_extract(pattern = '(\\b(?:[0-9]{1,3}\\.){3}[0-9]{1,3}\\b)')
  ip <- ip[!is.na(ip)]

  whois <- system2('whois', ip[1], stdout = TRUE)
  phones <- whois %>%
    grep(pattern = "Phone", value = TRUE, ignore.case = TRUE) %>%
      str_squish() %>%
        str_split(pattern = " ") %>%
          data.table::transpose() %>%
            .[[2]] %>%
              unique() %>%
                str_c(collapse = " ")
  
  netblock <- whois %>%
    grep(pattern = "CIDR", value = TRUE, ignore.case = TRUE) %>%
      str_squish() %>%
        str_split(pattern = " ", simplify = TRUE) %>%
          .[-1] %>%
            str_c(collapse = " ")
  
  country <- whois %>%
    grep(pattern = "Country", value = TRUE, ignore.case = TRUE) %>%
      str_squish() %>%
        str_split(pattern = " ", simplify = TRUE) %>%
          .[-1]
  
  country_state <- whois %>%
    grep(pattern = "State", value = TRUE, ignore.case = TRUE) %>%
      str_squish() %>%
        str_split(pattern = " ", simplify = TRUE) %>%
          .[-1]
  if(length(country_state)==0) country_state <- NA
  
  address <- whois %>%
  grep(pattern = "address", value = TRUE, ignore.case = TRUE) %>%
    str_squish() %>% 
      str_split(pattern = " ", simplify = TRUE) %>%
        .[-1] %>%
          str_c(collapse = " ")
  
  hosting <- whois %>%
    grep(pattern = "Hosting",
      value = TRUE,
        ignore.case = TRUE) %>%
          str_squish() %>%
            str_split(pattern = " ")
  hosting <- lapply(hosting, collapse = " ", str_c) %>%
    str_c(collapse = " ")
  
  nmap <-
    system2('nmap', args = c('-p', '22,21,80,443', ip[1]), stdout = TRUE)
  ports <- nmap %>%
    grep(pattern = "open", value = TRUE, ignore.case = TRUE) %>%
      str_squish() %>%
        str_split(pattern = " ") %>%
          data.table::transpose() %>%
            .[[1]] %>%
              str_c(collapse = " ")
  
  ip <- str_c(ip,collapse = ' ')
  company_sum <- data.frame(csum = c(company_url, ip, netblock, country, country_state, address, phones, hosting, ports), 
                 row.names = c('company_url', 'ip', 'netblock', 'country', 'country_state', 'address', 'phones', 'hosting', 'ports'))
  company_sum
}
urls <- c("Googleblog.blogspot.com", "Teradata.com", "Smithmicro.com", "Hitachi.com", "Gateway.com", "Research.microsoft.com", "Aspiresys.com", "Crossriver.com", "Packardbell.com", "Vertica.com", "Sun.com", "Scnsoft.com", "Dmoz.org", "Mom.me", "Avs4you.com")
  
dfs <- lapply(urls, get_sum_df)
result <- bind_cols(dfs) 
row.names(result) <- c('company_url', 'ip', 'netblock', 'country', 'country_state', 'address', 'phones', 'hosting', 'ports')
colnames(result) <- map(result[1,],as.character) %>% 
  unlist()
result <- result[-1,]
knitr::kable(result)
```

```{r, cache=TRUE, message=FALSE, warning=FALSE}
library(rappalyzer)
rappalyze("Googleblog.blogspot.com")
rappalyze("Teradata.com")
rappalyze("Smithmicro.com")
rappalyze("Hitachi.com")
rappalyze("Gateway.com")
rappalyze("Research.microsoft.com")
rappalyze("Aspiresys.com")
rappalyze("Crossriver.com")
rappalyze("Packardbell.com")
rappalyze("Vertica.com")
rappalyze("Sun.com")
rappalyze("Scnsoft.com")
rappalyze("Dmoz.org")
rappalyze("Mom.me")
rappalyze("Avs4you.com")
```